import os
from dotenv import load_dotenv
import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from dotenv import load_dotenv
import os



# .env dosyasÄ±nÄ± proje kÃ¶kÃ¼nden yÃ¼kle
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))

# âœ… Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# âœ… API anahtarÄ±nÄ± .envâ€™den Ã§ek
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# ğŸ“ FAISS dizini
DB_DIR = os.path.join(os.path.dirname(__file__), "db", "faiss")

# ğŸ”¢ Embedding modeli
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ§  FAISS veritabanÄ±nÄ± yÃ¼kle
db = FAISS.load_local(DB_DIR, embeddings, allow_dangerous_deserialization=True)

# ğŸš€ Gemini modelini baÅŸlat
model = genai.GenerativeModel("gemini-2.5-flash")

def ask_gemini(question: str):
    """FAISS + Gemini tabanlÄ± akÄ±llÄ± cevaplama"""
    try:
        # ğŸ”¹ FAISS'ten ilgili dokÃ¼manlarÄ± getir
        docs = db.similarity_search(question, k=5)
        context = "\n\n".join([doc.page_content for doc in docs])

        # ğŸ”¹ Prompt oluÅŸtur
        prompt = f"""
        Sen bir bankacÄ±lÄ±k destek asistanÄ±sÄ±n.
        AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak kullanÄ±cÄ±nÄ±n sorusuna net ve doÄŸru bir yanÄ±t ver.

        BaÄŸlam:
        {context}

        Soru:
        {question}

        Cevap:
        """

        # ğŸ”¹ Gemini'den yanÄ±t al
        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        return f"Bir hata oluÅŸtu: {e}"
