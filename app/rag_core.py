import os
from dotenv import load_dotenv
import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from datasets import load_dataset  # âœ… FAISS yeniden inÅŸa iÃ§in gerekli


# âœ… Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# ğŸ“ FAISS dizini
DB_DIR = os.path.join(os.path.dirname(__file__), "db", "faiss")

# ğŸ”¢ Embedding modeli
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ”¹ Veri setleri (FAISS yeniden oluÅŸturma durumunda kullanÄ±lacak)
DATASETS = [
    "wasifis/bank-assistant-qa",
    "bitext/Bitext-retail-banking-llm-chatbot-training-dataset",
]


def build_faiss_index():
    """Cloud ortamÄ±nda FAISS index yoksa otomatik oluÅŸturur."""
    try:
        texts = []
        for name in DATASETS:
            print(f"ğŸ“¥ {name} yÃ¼kleniyor...")
            ds = load_dataset(name)
            split = ds["train"] if "train" in ds else ds[list(ds.keys())[0]]

            for row in split:
                q = row.get("question") or row.get("query") or row.get("user_input") or ""
                a = row.get("answer") or row.get("response") or ""
                if q and a:
                    texts.append(f"Soru: {q}\nCevap: {a}")

        print("ğŸ§© Embedding ve FAISS index oluÅŸturuluyor...")
        db_local = FAISS.from_texts(texts, embeddings)
        os.makedirs(DB_DIR, exist_ok=True)
        db_local.save_local(DB_DIR)
        print("âœ… FAISS index baÅŸarÄ±yla oluÅŸturuldu.")
        return db_local
    except Exception as e:
        print(f"âŒ FAISS index oluÅŸturulamadÄ±: {e}")
        return None


# ğŸ§  FAISS veritabanÄ±nÄ± yÃ¼kle veya oluÅŸtur
try:
    db = FAISS.load_local(DB_DIR, embeddings, allow_dangerous_deserialization=True)
    print("âœ… FAISS index yÃ¼klendi.")
except Exception:
    print("âš ï¸ FAISS index bulunamadÄ±, yeniden oluÅŸturuluyor...")
    db = build_faiss_index()

# ğŸš€ Gemini modelini baÅŸlat
model = genai.GenerativeModel("gemini-2.5-flash")


def ask_gemini(question: str):
    """FAISS + Gemini tabanlÄ± akÄ±llÄ± cevaplama"""
    try:
        if db is None:
            return "FAISS veritabanÄ± oluÅŸturulamadÄ±, lÃ¼tfen yeniden baÅŸlatÄ±n."

        # ğŸ”¹ FAISS'ten ilgili dokÃ¼manlarÄ± getir
        docs = db.similarity_search(question, k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        # ğŸ”¹ Prompt oluÅŸtur
        prompt = f"""
        Sen bir bankacÄ±lÄ±k destek asistanÄ±sÄ±n.
        AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak kullanÄ±cÄ±nÄ±n sorusuna net ve doÄŸru bir yanÄ±t ver.

        BaÄŸlam:
        {context}

        Soru:
        {question}

        Cevap:
        """

        # ğŸ”¹ Gemini'den yanÄ±t al
        response = model.generate_content(prompt, request_options={"timeout": 30})

        return response.text

    except Exception as e:
        return f"Bir hata oluÅŸtu: {e}"
