import os
from dotenv import load_dotenv
import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from datasets import load_dataset  # âœ… FAISS yeniden inÅŸa iÃ§in gerekli
import time


# âœ… Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# ğŸ“ FAISS dizini
DB_DIR = os.path.join(os.path.dirname(__file__), "db", "faiss")

# ğŸ”¢ Embedding modeli
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ”¹ Veri setleri (FAISS yeniden oluÅŸturma durumunda kullanÄ±lacak)
DATASETS = [
    "wasifis/bank-assistant-qa",
    "bitext/Bitext-retail-banking-llm-chatbot-training-dataset",
]


def build_faiss_index():
    """Cloud ortamÄ±nda FAISS index yoksa otomatik oluÅŸturur."""
    try:
        texts = []
        for name in DATASETS:
            print(f"ğŸ“¥ {name} yÃ¼kleniyor...")
            ds = load_dataset(name)
            split = ds["train"] if "train" in ds else ds[list(ds.keys())[0]]

            for row in split:
                q = row.get("question") or row.get("query") or row.get("user_input") or ""
                a = row.get("answer") or row.get("response") or ""
                if q and a:
                    texts.append(f"Soru: {q}\nCevap: {a}")

        print("ğŸ§© Embedding ve FAISS index oluÅŸturuluyor...")
        db_local = FAISS.from_texts(texts, embeddings)
        os.makedirs(DB_DIR, exist_ok=True)
        db_local.save_local(DB_DIR)
        print("âœ… FAISS index baÅŸarÄ±yla oluÅŸturuldu.")
        return db_local
    except Exception as e:
        print(f"âŒ FAISS index oluÅŸturulamadÄ±: {e}")
        return None


# ğŸ§  FAISS veritabanÄ±nÄ± yÃ¼kle veya oluÅŸtur
try:
    db = FAISS.load_local(DB_DIR, embeddings, allow_dangerous_deserialization=True)
    print("âœ… FAISS index yÃ¼klendi.")
except Exception:
    print("âš ï¸ FAISS index bulunamadÄ±, yeniden oluÅŸturuluyor...")
    db = build_faiss_index()

# ğŸš€ Gemini modelini baÅŸlat
model = genai.GenerativeModel("gemini-2.5-flash")


def ask_gemini(question: str):
    """FAISS + Gemini tabanlÄ± akÄ±llÄ± cevaplama (streaming + timeout ile optimize edilmiÅŸ)"""
    try:
        if db is None:
            return "FAISS veritabanÄ± oluÅŸturulamadÄ±, lÃ¼tfen yeniden baÅŸlatÄ±n."

        start_time = time.time()

        # ğŸ”¹ FAISS'ten ilgili dokÃ¼manlarÄ± getir (daha kÃ¼Ã§Ã¼k k deÄŸeriyle)
        docs = db.similarity_search(question, k=2)
        context = "\n\n".join([doc.page_content for doc in docs])

        # ğŸ”¹ Prompt oluÅŸtur
        prompt = f"""
        Sen bir bankacÄ±lÄ±k destek asistanÄ±sÄ±n.
        AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak kullanÄ±cÄ±nÄ±n sorusuna aÃ§Ä±k, kÄ±sa ve doÄŸru bir yanÄ±t ver.

        BaÄŸlam:
        {context}

        Soru:
        {question}

        Cevap:
        """

        # ğŸ”¹ Gemini'den streaming modunda yanÄ±t al (timeout korumalÄ±)
        response = model.generate_content(
            prompt,
            stream=True,
            request_options={"timeout": 25},
            generation_config={"max_output_tokens": 256}
        )

        result_text = ""
        for chunk in response:
            if chunk.text:
                result_text += chunk.text
            # 30 saniye limit korumasÄ± (Streamlit Cloud safety)
            if time.time() - start_time > 28:
                return "â±ï¸ YanÄ±t sÃ¼resi aÅŸÄ±ldÄ±, lÃ¼tfen tekrar deneyin."

        return result_text.strip() or "âš ï¸ Model bir yanÄ±t dÃ¶ndÃ¼remedi."

    except Exception as e:
        if "Deadline" in str(e) or "504" in str(e):
            return "â±ï¸ Sunucu yanÄ±t sÃ¼resi doldu â€” lÃ¼tfen tekrar deneyin."
        return f"Bir hata oluÅŸtu: {e}"
